# Introducci√≥n a los modelos GPT y su aplicaci√≥n en la programaci√≥n

## Objetivo general

Comprender la base conceptual y arquitect√≥nica de los modelos GPT, su proceso de entrenamiento y evoluci√≥n, para utilizarlos de forma informada y efectiva en tareas de programaci√≥n y desarrollo de software.

## ¬øQu√© es un modelo GPT?

**GPT** proviene de _Generative Pretrained Transformer_ y describe una **arquitectura de modelo de lenguaje**, no una marca espec√≠fica.

```{admonition} Significado de GPT
:class: tip

* **Generative** ‚Üí El modelo puede *generar* texto (no solo analizarlo o clasificarlo).
* **Pretrained** ‚Üí Ha sido *preentrenado* con grandes vol√∫menes de datos antes de afinarse en tareas espec√≠ficas.
* **Transformer** ‚Üí Utiliza mecanismos de *autoatenci√≥n (self-attention)* para procesar y generar secuencias de texto de manera contextual.
```

Los GPT forman parte de una familia de **redes neuronales profundas _(deep learning)_ basadas en la arquitectura** `Transformer`, dise√±adas para procesar y generar texto de forma coherente y contextual.

En esencia, un modelo GPT analiza consultas en lenguaje natural (denominadas _prompts_) y predice la respuesta m√°s probable bas√°ndose en patrones aprendidos durante su entrenamiento.

La arquitectura Transformer permite al modelo enfocarse en distintas partes del texto de entrada simult√°neamente, capturando mejor las relaciones contextuales y mejorando el rendimiento en tareas de procesamiento de lenguaje natural _(Natural Language Processing, NLP)_.

![](../_static/encodingword2.png)

**Figura 1:** Visualizaci√≥n del mecanismo de autoatenci√≥n _(self-attention)_ en un modelo Transformer. Cada matriz muestra c√≥mo el modelo distribuye su atenci√≥n entre las palabras de la oraci√≥n _‚ÄúThe animal didn‚Äôt cross the street because it was too tired‚Äù_. En la imagen izquierda, la atenci√≥n est√° m√°s dispersa: el modelo analiza m√∫ltiples relaciones entre palabras sin un foco sem√°ntico claro. En la imagen derecha, a medida que avanza el entrenamiento o las capas de la red, la atenci√≥n se vuelve m√°s espec√≠fica: el modelo asocia correctamente ‚Äúit‚Äù con ‚Äúthe animal‚Äù, demostrando c√≥mo el Transformer aprende dependencias contextuales de largo alcance. Fuente: Adaptado de Jay Alammar, ‚ÄúThe Illustrated Transformer‚Äù (2018). Disponible en [GitHub](https://jalammar.github.io/illustrated-transformer/).

## Arquitectura b√°sica de un _Transformer_

Un modelo Transformer se compone de dos m√≥dulos principales:

### 1. Codificador (_Encoder_)

El codificador convierte el texto en _embeddings_, que son representaciones num√©ricas de las palabras en un espacio vectorial.  
En este espacio, las palabras con significados similares tienden a ubicarse m√°s cerca unas de otras.

El encoder procesa estas _embeddings_ y asigna **pesos de atenci√≥n**, que indican la relevancia contextual de cada palabra dentro de la oraci√≥n. Adem√°s, los **codificadores posicionales** permiten que el modelo entienda el orden de las palabras, evitando ambig√ºedades en el significado.

### 2. Decodificador (_Decoder_)

El decodificador utiliza las representaciones vectoriales generadas por el encoder para **predecir la salida deseada**. Mediante mecanismos de autoatenci√≥n y c√°lculos probabil√≠sticos, el decodificador eval√∫a m√∫ltiples posibles continuaciones y selecciona la m√°s adecuada seg√∫n el contexto.

A diferencia de las redes neuronales recurrentes, los transformers **procesan toda la secuencia de texto simult√°neamente**, lo que permite **entrenamientos paralelos**.

```{figure} ../_static/transformer.png
:alt: transformer
:fig-align: center
:width: 300px
```

**Figura 2**: Arquitectura de un modelo GPT. Fuente: Vaswani et al., 2017. Disponible en [ArXiv](https://arxiv.org/abs/1706.03762v7).

## Ejemplos de modelos GPT y sus variantes

Aunque ChatGPT es el ejemplo m√°s conocido ‚Äîdesarrollado por **OpenAI** y basado en las arquitecturas **GPT-3.5** y **GPT-4**‚Äî, existen otros modelos de lenguaje desarrollados por distintas organizaciones:

| Modelo      | Desarrollador   | Enfoque principal                                                     |
| ----------- | --------------- | --------------------------------------------------------------------- |
| **GPT-5**   | OpenAI          | Evoluci√≥n de GPT-4, con mejoras en comprensi√≥n y generaci√≥n de texto. |
| **Claude**  | Anthropic       | Priorizaci√≥n de seguridad, alineaci√≥n √©tica y control de sesgos.      |
| **LLaMA**   | Meta            | Modelo eficiente y accesible, optimizado para investigaci√≥n.          |
| **Bard**    | Google          | Integraci√≥n entre generaci√≥n de texto y b√∫squeda en la web.           |
| **Gemini**  | Google DeepMind | Combinaci√≥n de lenguaje, razonamiento y capacidades multimodales.     |
| **Mistral** | Mistral AI      | Foco en eficiencia, rendimiento y modelos abiertos de alta calidad.   |

## ¬øPor qu√© existen tantos modelos GPT?

La diversidad de modelos GPT no se debe √∫nicamente a la competencia entre empresas, sino a la **evoluci√≥n continua de las t√©cnicas de entrenamiento** que buscan mejorar su rendimiento, especializaci√≥n y eficiencia.

Para comprender esta evoluci√≥n, es importante distinguir dos etapas estrechamente relacionadas en el desarrollo de los modelos de lenguaje: el **preentrenamiento** (_pre-training_) y el **postentrenamiento** (_post-training_).

Estas dos fases no son independientes:

**todo modelo postentrenado proviene necesariamente de un modelo preentrenado**.

El preentrenamiento establece la base del conocimiento general del lenguaje, mientras que el postentrenamiento adapta ese conocimiento a tareas concretas, contextos espec√≠ficos y comportamientos alineados con las necesidades humanas.

### Pre-training _(Preentrenamiento)_

Durante esta primera fase, el modelo aprende los _patrones generales del lenguaje_ a partir de grandes vol√∫menes de texto no etiquetado.

El objetivo es crear una base s√≥lida de comprensi√≥n ling√ºistica: gram√°tica, sem√°ntica y contexto, sin enfocarse a√∫n en tareas espec√≠ficas.

Ejemplos de modelos preentrenados incluyen `Word2Vec`, `BERT` y `GPT`.

Esta etapa define la _capacidad general de comprensi√≥n del modelo, pero no garantiza un comportamiento √∫til con objetivos humanos._

### Post-training _(Postentrenamiento)_

Una vez completado el preentrenamiento, el modelo pasa a una segunda fase: el **postentrenamiento**, donde se **refina y especializa** en tareas concretas o estilos de interacci√≥n espec√≠ficos.

Podemos decir que el postentrenamiento ‚Äúense√±a al modelo a aplicar lo que aprendi√≥‚Äù.

Aqu√≠ se ajusta para generar c√≥digo, traducir idiomas, responder preguntas, mantener conversaciones o realizar razonamientos complejos de manera m√°s coherente y segura.

El postentrenamiento combina varias t√©cnicas complementarias:

![](../_static/paradigms.png)

**Figura 3:** Principales paradigmas de postentrenamiento en modelos de lenguaje. Fuente: Tie, _et al._, 2025. Disponible en [ArXiv](https://arxiv.org/abs/2503.06072).

- **Fine-tuning:** ajuste supervisado con ejemplos y datos etiquetados que orientan al modelo hacia tareas espec√≠ficas.
- **Alignment:** alineaci√≥n con preferencias y valores humanos mediante m√©todos como _Reinforcement Learning with Human Feedback (RLHF)_ o _Direct Preference Optimization (DPO)_.
- **Reasoning y eficiencia:** optimizaci√≥n de la capacidad de razonamiento y reducci√≥n del costo computacional, por ejemplo, mediante _parameter-efficient fine-tuning (PEFT)_ o arquitecturas _Mixture of Experts (MoE)_.

Gracias a estas t√©cnicas, los modelos postentrenados ‚Äîcomo **GPT-4**, **Claude 3.5**, **LLaMA 3** o **Gemini 2.0**‚Äî logran un comportamiento m√°s preciso, alineado y adaptable.  
Cada nueva generaci√≥n representa una mejora sobre su base preentrenada, marcando un ciclo continuo de **aprendizaje general ‚Üí ajuste especializado ‚Üí evoluci√≥n del modelo**.

## Evoluci√≥n del postentrenamiento en los modelos GPT

La figura siguiente resume la evoluci√≥n hist√≥rica de las **t√©cnicas de post-training** aplicadas a los **Modelos de Lenguaje Grandes (LLMs)** desde **2018 hasta 2025**.

Cada etapa representa un avance metodol√≥gico clave que ha permitido que los modelos GPT ‚Äîy sus equivalentes desarrollados por otras organizaciones‚Äî se vuelvan m√°s **precisos, adaptables y eficientes**.

![](../_static/timeline.png)

**Figura 4:** L√≠nea de tiempo del desarrollo de t√©cnicas de postentrenamiento en modelos de lenguaje (2018‚Äì2025), mostrando los principales hitos y modelos representativos. Fuente: Tie, _et al._, 2025. Disponible en [ArXiv](https://arxiv.org/abs/2503.06072).

### Etapas principales de la evoluci√≥n

**2018‚Äì2021: Fundamentos del Fine-Tuning**

- Modelos como `T5`, `mT5`, y `FLAN` introdujeron la idea de _instrucci√≥n_ y _fine-tuning supervisado (SFT)_, sentando las bases del entrenamiento instruccional.
- Se consolid√≥ el enfoque ‚Äú_pre-train + fine-tune_‚Äù, donde los modelos generalistas se adaptan a tareas espec√≠ficas.

**2022: Nacimiento del Alignment con RLHF**

- OpenAI lanz√≥ **InstructGPT**, aplicando _Reinforcement Learning with Human Feedback (RLHF)_ para alinear los modelos con las preferencias humanas.
- Surgen otros modelos influyentes como `Flan-PaLM` y `Claude`, que fortalecen la seguridad y la alineaci√≥n √©tica.

**2023: Expansi√≥n y diversificaci√≥n**

- Aparecen t√©cnicas alternativas como **Direct Preference Optimization (DPO)** y enfoques multimodales (texto + imagen).
- En este periodo, el campo explota en variedad de m√©todos y arquitecturas, incluyendo _Mixture of Experts (MoE)_ para mejorar la eficiencia computacional.

**2024: Avances en razonamiento y especializaci√≥n**

- Modelos como `DeepSeek-V3`, `Gemini 2.0`, y `Claude 3.7` comienzan a centrarse en la **capacidad de razonamiento l√≥gico (Reasoning)**.
- Surgen t√©cnicas de **adaptaci√≥n por dominio (Domain Adaptation)** para √°reas espec√≠ficas como finanzas, salud o programaci√≥n.

**2025: Consolidaci√≥n y optimizaci√≥n**

- Modelos de nueva generaci√≥n como `GPT-5`, `Gemini 2.5`, `Grok-3`, y `DeepSeek-R1` integran m√∫ltiples paradigmas de postentrenamiento.
- Estas versiones combinan razonamiento, eficiencia y alineaci√≥n avanzada, marcando la madurez del desarrollo de LLMs.

## ¬øPara qu√© me sirve saber esto?

Comprender c√≥mo surgen y evolucionan los modelos GPT no es solo un dato hist√≥rico: es una **base pr√°ctica para usarlos mejor** en programaci√≥n y desarrollo de software.

Cada fase del entrenamiento ‚Äîdesde el preentrenamiento hasta el postentrenamiento‚Äî determina **c√≥mo piensa, razona y responde un modelo**.  
Conocer estas etapas te ayuda a entender **qu√© puedes esperar de un GPT** y **c√≥mo aprovecharlo seg√∫n su dise√±o y capacidades**.

Conocer las diferencias entre modelos (por ejemplo, GPT-4 vs Gemini o Claude) te da criterio para:

- Elegir el modelo adecuado seg√∫n la tarea (razonamiento, generaci√≥n, an√°lisis, etc.).

- Entender sus **limitaciones t√©cnicas y sesgos**.

- Dise√±ar _prompts_ m√°s precisos que aprovechen la estructura interna del modelo.

```{admonition} Mensaje clave
:class: tip

 üí° Esto convierte al programador o analista no solo en un usuario del GPT, sino en alguien capaz de **dialogar t√©cnicamente** con la inteligencia artificial, integr√°ndola de manera estrat√©gica en su flujo de trabajo.
```
